{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c81b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 17 19:49:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.57                 Driver Version: 581.57         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   40C    P8             10W /  320W |    2008MiB /  16376MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           16464    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           17712    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           17824    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           20884    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           20892    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           21736    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           22116    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           22356    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           24500    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           26432    C+G   ....0.3537.71\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           27568    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           30624    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           34372    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           40848    C+G   ...t.User\\DDPM.Subagent.User.exe      N/A      |\n",
      "|    0   N/A  N/A           43248    C+G   Z:\\tools\\Notepad++\\notepad++.exe      N/A      |\n",
      "|    0   N/A  N/A           49304    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           52724    C+G   ...rograms\\EmEditor\\EmEditor.exe      N/A      |\n",
      "|    0   N/A  N/A           55212    C+G   ...al\\Programs\\cursor\\Cursor.exe      N/A      |\n",
      "|    0   N/A  N/A           57692    C+G   ....0.3537.71\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           67624    C+G   ....0.3537.71\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           76172    C+G   ...yb3d8bbwe\\Notepad\\Notepad.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "NVIDIA GPU detected: True\n",
      "Current PyTorch version: 2.7.1+cu118\n",
      "CUDA available in PyTorch: True\n",
      "\n",
      "âœ… PyTorch with CUDA is properly configured!\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and install correct PyTorch version\n",
    "!nvidia-smi\n",
    "\n",
    "# Check if we have GPU hardware but PyTorch can't see it\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "has_nvidia_gpu = result.returncode == 0\n",
    "\n",
    "print(f\"NVIDIA GPU detected: {has_nvidia_gpu}\")\n",
    "\n",
    "# Try importing torch to check current version\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"Current PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available in PyTorch: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # If we have a GPU but PyTorch can't use it, we need to reinstall\n",
    "    if has_nvidia_gpu and not torch.cuda.is_available():\n",
    "        print(\"\\nâš ï¸ GPU detected but PyTorch is CPU-only!\")\n",
    "        print(\"Installing PyTorch with CUDA support...\")\n",
    "        %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --force-reinstall\n",
    "        print(\"\\nâœ… PyTorch with CUDA installed. Please restart the runtime: Runtime -> Restart runtime\")\n",
    "    elif not has_nvidia_gpu:\n",
    "        print(\"\\nâš ï¸ No GPU detected! In Colab, go to: Runtime -> Change runtime type -> Select GPU (e.g., T4 GPU)\")\n",
    "    else:\n",
    "        print(\"\\nâœ… PyTorch with CUDA is properly configured!\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06b3586-c8bb-4cb9-8772-944b7c8954d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f06b3586-c8bb-4cb9-8772-944b7c8954d7",
    "outputId": "b78f6213-5ad1-4a23-c23b-d042cc8e4691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 17 19:50:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.57                 Driver Version: 581.57         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   40C    P8              9W /  320W |    2018MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           16464    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           17712    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           17824    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           20884    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           20892    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           21736    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           22116    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           22356    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           24500    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           26432    C+G   ....0.3537.71\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           27568    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           30624    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           34372    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           40848    C+G   ...t.User\\DDPM.Subagent.User.exe      N/A      |\n",
      "|    0   N/A  N/A           43248    C+G   Z:\\tools\\Notepad++\\notepad++.exe      N/A      |\n",
      "|    0   N/A  N/A           49304    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           52724    C+G   ...rograms\\EmEditor\\EmEditor.exe      N/A      |\n",
      "|    0   N/A  N/A           55212    C+G   ...al\\Programs\\cursor\\Cursor.exe      N/A      |\n",
      "|    0   N/A  N/A           57692    C+G   ....0.3537.71\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           67624    C+G   ....0.3537.71\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           76172    C+G   ...yb3d8bbwe\\Notepad\\Notepad.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available in Colab\n",
    "!nvidia-smi\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "def show_image(image, label):\n",
    "    image = image.permute(1, 2, 0)\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ded67-615c-4efd-ab7d-73217abc62c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a0ded67-615c-4efd-ab7d-73217abc62c0",
    "outputId": "98ad5299-9ddd-4e9d-dfa7-055f80cea73b"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# device=\"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# resume training options\n",
    "resume_training = True\n",
    "\n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.name = \"resnet_152_sgd1\"\n",
    "        self.workers = 4\n",
    "        self.lr = 0.1\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 1e-4\n",
    "        self.lr_step_size = 30\n",
    "        self.lr_gamma = 0.1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.__dict__ == other.__dict__\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "params = Params()\n",
    "params, params.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4zjhG5lV0e8N",
   "metadata": {
    "id": "4zjhG5lV0e8N"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from pathlib import Path\n",
    "import scipy.io as sio  # pip install scipy\n",
    "from tqdm import tqdm    # pip install tqdm\n",
    "\n",
    "# 1) CHANGE THIS to your actual local path:\n",
    "IMAGENET_ROOT = Path(\"Z:\\era-v4\\era4-assign9 - org\\archive\\ILSVRC2012\")\n",
    "\n",
    "VAL_FLAT  = IMAGENET_ROOT / \"val\"                # flat folder (source)\n",
    "DEVKIT    = IMAGENET_ROOT / \"devkit\"\n",
    "VAL_OUT   = IMAGENET_ROOT / \"val_sorted\"         # output target folder\n",
    "\n",
    "VAL_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Load mapping: ILSVRC_ID â†’ WNID\n",
    "meta = sio.loadmat(str(DEVKIT / \"data\" / \"meta.mat\"), squeeze_me=True)['synsets']\n",
    "id_to_wnid = {\n",
    "    int(e['ILSVRC2012_ID']) : str(e['WNID'])\n",
    "    for e in meta\n",
    "    if 1 <= int(e['ILSVRC2012_ID']) <= 1000\n",
    "}\n",
    "\n",
    "# 3) Read the ground-truth class for each image (alphabetically sorted order)\n",
    "gt_file = DEVKIT / \"data\" / \"ILSVRC2012_validation_ground_truth.txt\"\n",
    "gt_ids  = [int(x) for x in open(gt_file).read().strip().splitlines()]\n",
    "\n",
    "val_files = sorted(p for p in VAL_FLAT.glob(\"*.JPEG\"))\n",
    "assert len(val_files) == 50000, f\"Expected 50k val images, got {len(val_files)}\"\n",
    "assert len(val_files) == len(gt_ids), \"Mismatch between files and labels\"\n",
    "\n",
    "print(\"Reorganizing validation images into class folders...\")\n",
    "\n",
    "# 4) Copy each image into val_sorted/<WNID>/\n",
    "for img_path, ilsvrc_id in tqdm(zip(val_files, gt_ids), total=len(val_files)):\n",
    "    wnid = id_to_wnid[ilsvrc_id]\n",
    "    class_dir = VAL_OUT / wnid\n",
    "    class_dir.mkdir(exist_ok=True)\n",
    "    dst = class_dir / img_path.name\n",
    "    shutil.copy2(img_path, dst)\n",
    "\n",
    "print(\"âœ… DONE â€” validation images are now in\", VAL_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Onmk4rEPr_00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Onmk4rEPr_00",
    "outputId": "3c32e3cf-b884-4124-a62e-5f1c8840f4ab"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ihj3_rO700X4",
   "metadata": {
    "id": "Ihj3_rO700X4"
   },
   "outputs": [],
   "source": [
    "%mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4xzgUFHm0ft9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4xzgUFHm0ft9",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f89493d3-c27d-474e-99b1-c6e26a05d6b4"
   },
   "outputs": [],
   "source": [
    "!cp drive/MyDrive/data/imagenet/imagenet_subset.zip data/\n",
    "!cp drive/MyDrive/data/imagenet/imagenet_val.zip data/\n",
    "!unzip /content/data/archive.zip -d /content/data/\n",
    "!unzip /content/data/imagenet_val.zip -d /content/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rEh6-fttzQaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEh6-fttzQaa",
    "outputId": "19e44de6-9b41-4b10-e804-a57617c35736"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z1UZz06R804Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1UZz06R804Q",
    "outputId": "99e4780a-f694-4142-f03d-aa93b847cd81"
   },
   "outputs": [],
   "source": [
    "!unzip /content/data/imagenet_subset.zip -d /content/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42711da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! for %f in (data\\*.tar) do tar -xvf \"%f\" -C content\\data\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-0AnSnte8mYf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0AnSnte8mYf",
    "outputId": "4c5f827e-325c-40f0-ac67-373aeb8ce2e6"
   },
   "outputs": [],
   "source": [
    "! ls /content/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DB6NoBv3zT-t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "DB6NoBv3zT-t",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "bae525db-a419-4709-e5cc-a8be10762ff5"
   },
   "outputs": [],
   "source": [
    "!ls /content/data/imagenet_subtrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ba847-2b7a-478b-b3bf-73e2988e4595",
   "metadata": {
    "id": "ba5ba847-2b7a-478b-b3bf-73e2988e4595"
   },
   "outputs": [],
   "source": [
    "training_folder_name = 'data-train'\n",
    "val_folder_name = 'data-val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D-h3MxGd1utp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-h3MxGd1utp",
    "outputId": "bd97b406-c8b5-42f4-c267-4dc431e004cf"
   },
   "outputs": [],
   "source": [
    "os.listdir(training_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be1f5f-9eed-4afd-9dd3-1469e806d72c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4be1f5f-9eed-4afd-9dd3-1469e806d72c",
    "outputId": "dd371f28-deec-40bb-d4ff-d5577c53f35a"
   },
   "outputs": [],
   "source": [
    "os.listdir(training_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b4f03-ff29-4ab4-b79b-c96dfccc0551",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "990b4f03-ff29-4ab4-b79b-c96dfccc0551",
    "outputId": "a4780659-2be1-421a-e0d7-50e1a0d2d183"
   },
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomResizedCrop(224, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=training_folder_name,\n",
    "    transform=train_transformation\n",
    ")\n",
    "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=params.batch_size,\n",
    "    sampler=train_sampler,\n",
    "    num_workers = params.workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "for X, y in train_loader:\n",
    "    break\n",
    "print(X.shape)\n",
    "show_image(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881862d6-1704-4300-b009-c13a0434d685",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "881862d6-1704-4300-b009-c13a0434d685",
    "outputId": "d40f90c4-4104-4a1e-d3ab-56b17227ce6e"
   },
   "outputs": [],
   "source": [
    "train_dataset[1337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850ffa1-96ce-4a13-9731-b9ec39fddaed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a850ffa1-96ce-4a13-9731-b9ec39fddaed",
    "outputId": "1159ae40-4238-40aa-ca4f-8827e8b707f1"
   },
   "outputs": [],
   "source": [
    "val_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(size=256, antialias=True),\n",
    "        transforms.CenterCrop(224),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=val_folder_name,\n",
    "    transform=val_transformation\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=params.workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "for X, y in val_loader:\n",
    "    break\n",
    "print(X.shape)\n",
    "show_image(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yolgYe7cFSM-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yolgYe7cFSM-",
    "outputId": "bc9a00f6-ce1a-493b-d912-d3ff0c5b0973"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "def dataset_eda(train_dataset, val_dataset):\n",
    "    print(\"ðŸ“Š EDA on ImageNet Subset\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total Training Images: {len(train_dataset)}\")\n",
    "    print(f\"Total Validation Images: {len(val_dataset)}\")\n",
    "    print(f\"Number of Classes: {len(train_dataset.classes)}\\n\")\n",
    "\n",
    "    # Print first few class names\n",
    "    print(\"Sample Class Names:\", train_dataset.classes[:10], \"\\n\")\n",
    "\n",
    "    # Count images per class\n",
    "    train_counts = Counter([train_dataset.targets[i] for i in range(len(train_dataset))])\n",
    "    val_counts = Counter([val_dataset.targets[i] for i in range(len(val_dataset))])\n",
    "\n",
    "    # Convert to sorted lists for visualization\n",
    "    class_indices = list(range(len(train_dataset.classes)))\n",
    "    train_freqs = [train_counts[i] for i in class_indices]\n",
    "    val_freqs = [val_counts[i] for i in class_indices]\n",
    "\n",
    "    # Plot class distribution (Top 30 only for readability)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=list(range(min(30, len(train_freqs)))), y=train_freqs[:30])\n",
    "    plt.title(\"Training Samples per Class (Top 30)\")\n",
    "    plt.xlabel(\"Class Index\")\n",
    "    plt.ylabel(\"Image Count\")\n",
    "    plt.show()\n",
    "\n",
    "    # Show a few sample images\n",
    "    print(\"\\nðŸ–¼ï¸ Sample Images from Training Set:\")\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        idx = np.random.randint(len(train_dataset))\n",
    "        img, label = train_dataset[idx]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = np.clip((img * 0.229 + 0.485), 0, 1)  # De-normalize for viewing\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(train_dataset.classes[label][:15])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run EDA\n",
    "dataset_eda(train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e690d8-ee01-460f-a564-dd8d2c25d3b4",
   "metadata": {
    "id": "d1e690d8-ee01-460f-a564-dd8d2c25d3b4"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def train(dataloader, model, loss_fn, optimizer, epoch, writer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    start0 = time.time()\n",
    "    start = time.time()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_size = len(X)\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}], {(current/size * 100):>4f}%\")\n",
    "            step = epoch * size + current\n",
    "            writer.add_scalar('training loss',\n",
    "                            loss,\n",
    "                            step)\n",
    "            new_start = time.time()\n",
    "            delta = new_start - start\n",
    "            start = new_start\n",
    "            if batch != 0:\n",
    "                print(\"Done in \", delta, \" seconds\")\n",
    "                remaining_steps = size - current\n",
    "                speed = 100 * batch_size / delta\n",
    "                remaining_time = remaining_steps / speed\n",
    "                print(\"Remaining time (seconds): \", remaining_time)\n",
    "        optimizer.zero_grad()\n",
    "    print(\"Entire epoch done in \", time.time() - start0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf59e3d-06c3-4c89-8bb6-3cbd49ebd5b7",
   "metadata": {
    "id": "0cf59e3d-06c3-4c89-8bb6-3cbd49ebd5b7"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, epoch, writer, train_dataloader, calc_acc5=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            if calc_acc5:\n",
    "                _, pred_top5 = pred.topk(5, 1, largest=True, sorted=True)\n",
    "                correct_top5 += pred_top5.eq(y.view(-1, 1).expand_as(pred_top5)).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    step = epoch * len(train_dataloader.dataset)\n",
    "    if writer != None:\n",
    "        writer.add_scalar('test loss',\n",
    "                            test_loss,\n",
    "                            step)\n",
    "    correct /= size\n",
    "    correct_top5 /= size\n",
    "    if writer != None:\n",
    "        writer.add_scalar('test accuracy',\n",
    "                            100*correct,\n",
    "                            step)\n",
    "        if calc_acc5:\n",
    "            writer.add_scalar('test accuracy5',\n",
    "                            100*correct_top5,\n",
    "                            step)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    if calc_acc5:\n",
    "        print(f\"Test Error: \\n Accuracy-5: {(100*correct_top5):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691742a-c777-43e2-af73-58e9495adf61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a691742a-c777-43e2-af73-58e9495adf61",
    "outputId": "e538db36-56ba-44f0-cd19-8c0e2db18992"
   },
   "outputs": [],
   "source": [
    "## testing a pretrained model to validate correctness of our dataset, transform and metrics code\n",
    "pretrained_model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT').to(device)\n",
    "start = time.time()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "test(val_loader, pretrained_model, loss_fn, epoch=0, writer=None, train_dataloader=train_loader, calc_acc5=True)\n",
    "print(\"Elapsed: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c912fcc-2ae7-41f0-8a7b-835e8bb8b763",
   "metadata": {
    "id": "8c912fcc-2ae7-41f0-8a7b-835e8bb8b763"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b2306-a7e3-481d-aa4a-e7d83e2889c1",
   "metadata": {
    "id": "506b2306-a7e3-481d-aa4a-e7d83e2889c1"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Type, Union\n",
    "from torch import Tensor\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\" https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        base_width: int = 64,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0))\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e92946-8b3b-4f5a-8169-a82d5f3cd73e",
   "metadata": {
    "id": "59e92946-8b3b-4f5a-8169-a82d5f3cd73e"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Bottleneck],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        width_per_group: int = 64,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.base_width, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    base_width=self.base_width,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f89b61-29ad-4c61-a02a-55df6c493b22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29f89b61-29ad-4c61-a02a-55df6c493b22",
    "outputId": "96f39176-0e09-4263-d670-642115cd1973"
   },
   "outputs": [],
   "source": [
    "# Use the device that was set earlier (should be cuda if available)\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"âš ï¸ CUDA is not available! Please enable GPU runtime in Colab: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "model = ResNet(Bottleneck, [3, 8, 36, 3]).to(device)\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "preds = model(X.to(device))\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee08a9-32af-4f99-b096-e1ecf3f4a4f3",
   "metadata": {
    "id": "5cee08a9-32af-4f99-b096-e1ecf3f4a4f3"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=params.lr, momentum=params.momentum, weight_decay=params.weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=params.lr_step_size, gamma=params.lr_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21320fbf-2223-4dd6-93d9-ca04a336c144",
   "metadata": {
    "id": "21320fbf-2223-4dd6-93d9-ca04a336c144"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "checkpoint_path = os.path.join(\"checkpoints\", params.name, f\"checkpoint.pth\")\n",
    "if resume_training and os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "    assert params == checkpoint[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0065791-1dea-462b-8e11-338f09132d98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "b0065791-1dea-462b-8e11-338f09132d98",
    "outputId": "92a1f5fe-8bc0-43e6-e730-791aafe80a38"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "Path(os.path.join(\"checkpoints\", params.name)).mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter('runs/' + params.name)\n",
    "test(val_loader, model, loss_fn, epoch=0, writer=writer, train_dataloader=train_loader, calc_acc5=True)\n",
    "for epoch in range(start_epoch, 100):\n",
    "    train(train_loader, model, loss_fn, optimizer, epoch=epoch, writer=writer)\n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"params\": params\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(\"checkpoints\", params.name, f\"model_{epoch}.pth\"))\n",
    "    torch.save(checkpoint, os.path.join(\"checkpoints\", params.name, f\"checkpoint.pth\"))\n",
    "    lr_scheduler.step()\n",
    "    test(val_loader, model, loss_fn, epoch + 1, writer, train_dataloader=train_loader, calc_acc5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WId5fLG556Tr",
   "metadata": {
    "id": "WId5fLG556Tr"
   },
   "outputs": [],
   "source": [
    "%mkdir /content/drive/MyDrive/projects/imagenet_poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bXyyOFe7S1M",
   "metadata": {
    "id": "5bXyyOFe7S1M"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/checkpoints/ /content/drive/MyDrive/projects/imagenet_poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JIE8joXp6MIr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIE8joXp6MIr",
    "outputId": "a7cafbca-7c5f-45f2-dc6f-f3fa783a43f5"
   },
   "outputs": [],
   "source": [
    "!ls /content/drive/MyDrive/projects/imagenet_poc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X14LlLup6Og4",
   "metadata": {
    "id": "X14LlLup6Og4"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/runs /content/drive/MyDrive/projects/imagenet_poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ue62OZtt6cSN",
   "metadata": {
    "id": "ue62OZtt6cSN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
